{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a282d61a-89f3-451e-a2ac-3f8df0662195",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a736607d-3153-4d11-abf0-464a81b5bbfc",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3358490829.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Toolbox for EOG et EMG -> Voir si y a des params importants\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Toolbox for EOG et EMG -> Voir si y a des params importants\n",
    "Faire du ML sur ces features et voir si y a des features importantes pr Ã§a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58707248-4538-4b42-b309-aef29b2cce73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os, mne, numpy as np, matplotlib.pyplot as plt, pandas as pd\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df3f8bd1-9728-4801-8910-1725ef9d63b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your path to the data\n",
    "main_path = \"../BCI_Database/Signals/DATA A/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6386250",
   "metadata": {},
   "source": [
    "#### Storing all the attributes of the subjects into a dataframe in order to separate them according to specific conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d1ee8c3-5843-4858-9b9a-909ab710e5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_attributes():\n",
    "    \n",
    "    #Retrieving attributes of all participants so we can separate them based on specific conditions\n",
    "    attributes_path = glob(\"../BCI_Database/*\")[3]\n",
    "    print(\"Path :\", attributes_path)\n",
    "\n",
    "    attributes = pd.read_excel(attributes_path, header = None)\n",
    "\n",
    "    attributes.columns = attributes.iloc[2]\n",
    "    attributes = attributes.iloc[3:63].reset_index(drop=True)\n",
    "\n",
    "    names = attributes.columns.tolist()\n",
    "    print(\"Columns :\", names)\n",
    "\n",
    "    for col in attributes.columns:\n",
    "        if attributes[col].isnull().sum() !=0:\n",
    "            print(col, attributes[col].isnull().sum())\n",
    "\n",
    "    #Using a dictionnary to fill NA values for every column that contains Na\n",
    "    D = {None : \"Nothing/Unknown\"}\n",
    "    attributes = attributes.replace(D)   \n",
    "    \n",
    "    #Reject every participant that had some issues in the EEG data acquisition\n",
    "    rejected = attributes[attributes['COMMENTS'] != \"Nothing/Unknown\"]['SUJ_ID']\n",
    "    rejected = rejected.tolist()\n",
    "\n",
    "\n",
    "    attributes = attributes[attributes['COMMENTS'] == \"Nothing/Unknown\"]\n",
    "    \n",
    "    attributes.to_csv('../attributes.csv', index=False)\n",
    "    \n",
    "    return attributes, rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4fde8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path : ../BCI_Database\\Perfomances.xlsx\n",
      "Columns : ['SUJ_ID', 'SUJ_gender', 'EXP_gender', 'COMMENTS', 'Perf_RUN_3', 'Perf_RUN_4', 'Perf_RUN_5', 'Perf_RUN_6', 'Birth_year', 'Vision', 'Vision_assistance', 'Symptoms', 'Level of study', 'Level_knowledge neuro', 'Meditation practice', 'Laterality answered', 'Manual activity', 'Manual activity_TXT', 'score', 'time_1', 'time_2', 'PRE_Mood', 'PRE_Mindfulness', 'PRE_Motivation', 'PRE_Hours_sleep_last_night', 'PRE_Usual_sleep', 'PRE_Level_of_alertness', 'PRE_Stimulant_doses_12h', 'PRE_Stimulant_doses_2h', 'PRE_Stim_normal', 'PRE_Tabacco', 'PRE_Tabacco_normal', 'PRE_Alcohol', 'PRE_Last_meal', 'PRE_Last_pills', 'PRE_Pills_TXT', 'POST_Mood', 'POST_Mindfulness', 'POST_Motivation', 'POST_Cognitive load', 'POST_Agentivity', 'POST_Expectations_filled', 'active', 'reflexive', 'sensory', 'intuitive', 'visual', 'verbal', 'sequential', 'global', 'A', 'B', 'C', 'E', 'F', 'G', 'H', 'I', 'L', 'M', 'N', 'O', 'Q1', 'Q2', 'Q3', 'Q4', 'IM', 'EX', 'AX', 'TM', 'IN', 'SC', 'Interrogation']\n",
      "COMMENTS 42\n",
      "Perf_RUN_5 1\n",
      "Perf_RUN_6 1\n",
      "Meditation practice 8\n",
      "Manual activity_TXT 5\n",
      "PRE_Tabacco_normal 2\n",
      "PRE_Pills_TXT 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_18364\\977391799.py:21: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  attributes = attributes.replace(D)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>2</th>\n",
       "      <th>SUJ_ID</th>\n",
       "      <th>SUJ_gender</th>\n",
       "      <th>EXP_gender</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>Perf_RUN_3</th>\n",
       "      <th>Perf_RUN_4</th>\n",
       "      <th>Perf_RUN_5</th>\n",
       "      <th>Perf_RUN_6</th>\n",
       "      <th>Birth_year</th>\n",
       "      <th>Vision</th>\n",
       "      <th>...</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>IM</th>\n",
       "      <th>EX</th>\n",
       "      <th>AX</th>\n",
       "      <th>TM</th>\n",
       "      <th>IN</th>\n",
       "      <th>SC</th>\n",
       "      <th>Interrogation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nothing/Unknown</td>\n",
       "      <td>67.5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>95</td>\n",
       "      <td>82.5</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Nothing/Unknown</td>\n",
       "      <td>100.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>100</td>\n",
       "      <td>1969</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Nothing/Unknown</td>\n",
       "      <td>55.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>55</td>\n",
       "      <td>50</td>\n",
       "      <td>1982</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Nothing/Unknown</td>\n",
       "      <td>62.5</td>\n",
       "      <td>42.5</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A8</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nothing/Unknown</td>\n",
       "      <td>50.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>60</td>\n",
       "      <td>57.5</td>\n",
       "      <td>1992</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>9.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "2 SUJ_ID  SUJ_gender  EXP_gender         COMMENTS  Perf_RUN_3  Perf_RUN_4  \\\n",
       "0     A1           1           1  Nothing/Unknown        67.5        92.5   \n",
       "2     A3           2           1  Nothing/Unknown       100.0        95.0   \n",
       "3     A4           1           1  Nothing/Unknown        55.0        45.0   \n",
       "6     A7           2           1  Nothing/Unknown        62.5        42.5   \n",
       "7     A8           1           2  Nothing/Unknown        50.0        57.4   \n",
       "\n",
       "2 Perf_RUN_5 Perf_RUN_6  Birth_year  Vision  ...  Q2  Q3  Q4  IM   EX   AX  \\\n",
       "0         95       82.5        1993       1  ...   7   3   8   5  4.7  9.1   \n",
       "2       97.5        100        1969       2  ...   6   3   5   7  5.5  4.2   \n",
       "3         55         50        1982       2  ...   7   2   7   3  5.8  6.8   \n",
       "6         45         40        1997       1  ...   5   5   3   6  7.7  5.0   \n",
       "7         60       57.5        1992       2  ...   6   5   7   2  6.3  9.7   \n",
       "\n",
       "2   TM   IN   SC  Interrogation  \n",
       "0  3.1  3.6  3.0             15  \n",
       "2  4.8  3.3  4.0              7  \n",
       "3  5.0  4.9  2.4              8  \n",
       "6  7.8  4.7  5.6              4  \n",
       "7  4.1  4.6  4.4              9  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A2', 'A5', 'A6', 'A9', 'A11', 'A13', 'A17', 'A21', 'A29', 'A31', 'A32', 'A36', 'A38', 'A39', 'A46', 'A47', 'A55', 'A60']\n"
     ]
    }
   ],
   "source": [
    "attributes, rejected = df_attributes()\n",
    "display(attributes.head())\n",
    "print(rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c9346c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We also delete A40 and A59 because of the missing data (see on the article)\n",
    "rejected.append(\"A40\")\n",
    "rejected.append(\"A59\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0fad87",
   "metadata": {},
   "source": [
    "This code will create dataframes depending on input files which can be :   \n",
    "- Acquisition only  \n",
    "- OnlineT only  \n",
    "- Acquisition + training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72fef361-a838-4390-b5a4-2d6e3a1c8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def files(main_path, baseline = False, acquisition = False, MI = True, rejected = []):\n",
    "    \n",
    "    #Copying the list since we will remove some subjects in the list\n",
    "    reject = rejected.copy()\n",
    "\n",
    "    single_digit = []\n",
    "    for suj in rejected:\n",
    "        \n",
    "        if len(suj) == 2:\n",
    "            single_digit.append(suj)\n",
    "            reject.remove(suj)\n",
    "        \n",
    "        #Win some time cause 2 digits subjects are after single digit ones\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    all_file_path = glob(main_path)\n",
    "\n",
    "    print(f\"Number of participants : {len(all_file_path)}\\n\")\n",
    "\n",
    "    all_file_path = [path for path in all_file_path if not any(substring in path.split('DATA')[1] for substring in reject)]\n",
    "    \n",
    "    #Remove A1 because of the acquisition which is shorter than other acquisition files\n",
    "    all_file_path.remove(\"../BCI_Database/Signals/DATA A\\\\A1\")\n",
    "\n",
    "    #Removing the subject with single digit\n",
    "    for path in single_digit:\n",
    "        all_file_path.remove(f\"../BCI_Database/Signals/DATA A\\\\{path}\")\n",
    "\n",
    "    print(\"Number of participants retained :\" , len(all_file_path))\n",
    "\n",
    "    all_baseline_path = []\n",
    "    if baseline :\n",
    "        all_baseline_path = []\n",
    "        for path in all_file_path:\n",
    "            path = glob(path + '/*baseline*')\n",
    "            all_baseline_path.append(path)\n",
    "    \n",
    "    all_acquisition_path = []\n",
    "    if acquisition :\n",
    "        for path in all_file_path:\n",
    "            path = glob(path + '/*acquisition*')\n",
    "            all_acquisition_path.append(path)\n",
    "\n",
    "    all_MI_path = []\n",
    "    if MI :\n",
    "        for path in all_file_path:\n",
    "            path = glob(path + '/*online*')\n",
    "            all_MI_path.append(path)\n",
    "\n",
    "    if baseline:\n",
    "        n = len(all_baseline_path)\n",
    "        \n",
    "    elif acquisition:\n",
    "        n = len(all_acquisition_path)\n",
    "\n",
    "    elif MI:\n",
    "        n = len(all_MI_path)\n",
    "\n",
    "    #Creating final list with empty sublists\n",
    "    L = [[] for _ in range(n)]\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        if baseline:\n",
    "            L[i].extend(all_baseline_path[i])\n",
    "\n",
    "        if acquisition:\n",
    "            L[i].extend(all_acquisition_path[i])\n",
    "\n",
    "        if MI:\n",
    "            L[i].extend(all_MI_path[i])\n",
    "    \n",
    "    #Find participants selected\n",
    "    pattern = r'A\\d+'\n",
    "\n",
    "    return L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c49aa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants : 60\n",
      "\n",
      "Number of participants retained : 39\n",
      "\n",
      "Number of files per participant : 6\n",
      "Files for participant A10 : ['../BCI_Database/Signals/DATA A\\\\A10\\\\A10_R1_acquisition.gdf', '../BCI_Database/Signals/DATA A\\\\A10\\\\A10_R2_acquisition.gdf', '../BCI_Database/Signals/DATA A\\\\A10\\\\A10_R3_onlineT.gdf', '../BCI_Database/Signals/DATA A\\\\A10\\\\A10_R4_onlineT.gdf', '../BCI_Database/Signals/DATA A\\\\A10\\\\A10_R5_onlineT.gdf', '../BCI_Database/Signals/DATA A\\\\A10\\\\A10_R6_onlineT.gdf']\n"
     ]
    }
   ],
   "source": [
    "all_files = files(main_path, baseline=False, acquisition=True, MI=True, rejected=rejected)\n",
    "print(f\"\\nNumber of files per participant : {len(all_files[0])}\\nFiles for participant A10 : {all_files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "205ad189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants : 60\n",
      "\n",
      "Number of participants retained : 39\n",
      "\n",
      "Number of files per participant : 2 \n",
      "Files for participant A10 : ['../BCI_Database/Signals/DATA A\\\\A10\\\\A10_CE_baseline.gdf', '../BCI_Database/Signals/DATA A\\\\A10\\\\A10_OE_baseline.gdf']\n"
     ]
    }
   ],
   "source": [
    "baseline_files = files(main_path, baseline=True, acquisition=False, MI=False, rejected=rejected)\n",
    "print(f\"\\nNumber of files per participant : {len(baseline_files[0])} \\nFiles for participant A10 : {baseline_files[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d759f861-8ee2-4edb-92cf-e70ac0361de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data\n",
    "def read_data(file_path):\n",
    "\n",
    "    # Excluding non EEG channels\n",
    "    electrodes_to_exclude = ['EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd']\n",
    "\n",
    "    # Importing data\n",
    "    data = mne.io.read_raw_gdf(file_path, exclude=electrodes_to_exclude, preload=True)\n",
    "\n",
    "    #We do not set_eeg_reference since the referencing have been already done on the earlobe and reference electrode is not included in the data\n",
    "\n",
    "    #Doing the minimum filtering (we're still on raw data but we filter out the drifting of EEG)\n",
    "    data.filter(l_freq=0.5, h_freq=50, method='iir')   #Forced to use bandpass filter so we have 50 as max frequency\n",
    "\n",
    "    #Creating events based on the article annotation (768 = begin of the trial, 769 = left-hand MI, 770 = right-hand MI)\n",
    "    events = mne.events_from_annotations(data, event_id={'768': 0, '769': 1, '770': 2})[0]\n",
    "\n",
    "    #Creating epochs for every trial\n",
    "    epochs = mne.Epochs(data, events, event_id={'start': 0}, tmin=0, tmax=8, baseline=(0, 2), preload=True) #Setting the baseline to the first two seconds of each trial (Fig.5 of the article)\n",
    "    \n",
    "    array = epochs['start'].get_data(copy=True)\n",
    "\n",
    "    #Retrieving the sampling rate\n",
    "    global sfreq\n",
    "    sfreq = int(data.info['sfreq'])\n",
    "\n",
    "    #Retrieving channel names\n",
    "    global channel_names\n",
    "    channel_names = epochs.ch_names\n",
    "\n",
    "    print(f\"\\nSampling rate : {sfreq}\")\n",
    "    return array, events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c93d2e17-6dfd-4053-ba3e-ae54fff14fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\gricih01\\OneDrive - UniversitÃ© du QuÃ©bec en Outaouais\\Documents\\MI BCI Database and scripts\\Scripts\\A5_R1_acquisition.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "Fz, FCz, Cz, CPz, Pz, C1, C3, C5, C2, C4, C6, F4, FC2, FC4, FC6, CP2, CP4, CP6, P4, F3, FC1, FC3, FC5, CP1, CP3, CP5, P3\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 230431  =      0.000 ...   450.061 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 50.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Used Annotations descriptions: ['768', '769', '770']\n",
      "Not setting metadata\n",
      "40 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 4097 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n",
      "Sampling rate : 512\n"
     ]
    }
   ],
   "source": [
    "sample_data, events = read_data(all_files[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a41c7b5-8faa-4643-ada9-b284afdc6e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 27, 4097)\n",
      "(80, 3)\n"
     ]
    }
   ],
   "source": [
    "print(sample_data.shape) #nb of windows, channels, nb of points for each signal\n",
    "print(events.shape)\n",
    "del sample_data\n",
    "del events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "771eed1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_baseline(file_path):\n",
    "\n",
    "    # Excluding non EEG channels\n",
    "    electrodes_to_exclude = ['EOG1', 'EOG2', 'EOG3', 'EMGg', 'EMGd']\n",
    "\n",
    "    eog_channels = ['EOG1', 'EOG2', 'EOG3']\n",
    "    \n",
    "    # Importing data\n",
    "    data = mne.io.read_raw_gdf(file_path, eog=eog_channels, exclude=electrodes_to_exclude, preload=True)\n",
    "\n",
    "    #We do not set_eeg_reference since the referencing have been already done on the earlobe and reference electrode is not included in the data\n",
    "\n",
    "    #Doing the minimum filtering (we're still on raw data but we filter out the drifting of EEG)\n",
    "    data.filter(l_freq=0.5, h_freq=50, method='iir', n_jobs=-1)   #Power line noise = 50Hz (Verified on graph + classic Europpean noise line)\n",
    "\n",
    "    #Creating epochs (same # of epochs as the old one)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration = 4.6, overlap = 0)    \n",
    "\n",
    "    array = epochs.get_data(picks='eeg', copy=True)\n",
    "    \n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "152111c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from c:\\Users\\gricih01\\OneDrive - UniversitÃ© du QuÃ©bec en Outaouais\\Documents\\MI BCI Database and scripts\\BCI_Database\\Signals\\DATA A\\A10\\A10_CE_baseline.gdf...\n",
      "GDF file detected\n",
      "Setting channel info structure...\n",
      "Could not determine channel type of the following channels, they will be set as EEG:\n",
      "Fz, FCz, Cz, CPz, Pz, C1, C3, C5, C2, C4, C6, F4, FC2, FC4, FC6, CP2, CP4, CP6, P4, F3, FC1, FC3, FC5, CP1, CP3, CP5, P3\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 95775  =      0.000 ...   187.061 secs...\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.5 - 50 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 0.50, 50.00 Hz: -6.02, -6.02 dB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "40 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 40 events and 2355 original time points ...\n",
      "0 bad epochs dropped\n",
      "\n",
      "(40, 27, 2355)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    9.5s finished\n"
     ]
    }
   ],
   "source": [
    "baseline_sample = read_baseline(baseline_files[0][0])\n",
    "print(f'\\n\\n{baseline_sample.shape}')\n",
    "#del baseline_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "40a283f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of the channels : ['Fz', 'FCz', 'Cz', 'CPz', 'Pz', 'C1', 'C3', 'C5', 'C2', 'C4', 'C6', 'F4', 'FC2', 'FC4', 'FC6', 'CP2', 'CP4', 'CP6', 'P4', 'F3', 'FC1', 'FC3', 'FC5', 'CP1', 'CP3', 'CP5', 'P3']\n"
     ]
    }
   ],
   "source": [
    "print(f\"Names of the channels : {channel_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bf1c30de-313d-4d46-9d64-cdb6e24ec799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_data(all_files):\n",
    "\n",
    "    #Label array to store every ID for each participant\n",
    "    label_subject_acquisition = []\n",
    "    label_subject_MI = []\n",
    "\n",
    "    #Regex pattern to find the ID of the subject\n",
    "    pattern = r'A\\d+'\n",
    "\n",
    "    data_acquisition_list = []  #Metadata of the acquisition\n",
    "    data_MI_list = []           #Metadata of the MI\n",
    "\n",
    "    events_acquisition = []            #Storing the events for every signal\n",
    "    events_MI = []            #Storing the events for every signal\n",
    "\n",
    "    for subject_files in all_files:\n",
    "        \n",
    "        #Storing acquisition for each subject (each signal selected)\n",
    "        data_subject_acquisition = []\n",
    "\n",
    "        #Storing MI for each subject\n",
    "        data_subject_MI = []\n",
    "        label = re.findall(pattern, subject_files[0])[0]\n",
    "\n",
    "        for j in subject_files:\n",
    "\n",
    "            data, event = read_data(j)\n",
    "\n",
    "            if 'acquisition' in j:\n",
    "                data_subject_acquisition.append(data)\n",
    "                events_acquisition.append(event)\n",
    "\n",
    "            elif 'onlineT' in j:\n",
    "                data_subject_MI.append(data)\n",
    "                events_MI.append(event)\n",
    "\n",
    "        \n",
    "        #Creating the array and reshaping it (#files, # epochs, #channels, resolution) -> (#epochs * #files, #channels, #resolution)\n",
    "        data_subject_acquisition = np.array(data_subject_acquisition)\n",
    "\n",
    "        #Reshaping acquisition matrix\n",
    "        files_acquisition, epochs_acquisition, channels_acquisition, resolution_acquisition = data_subject_acquisition.shape\n",
    "        data_subject_acquisition = data_subject_acquisition.reshape((files_acquisition*epochs_acquisition, channels_acquisition, resolution_acquisition))\n",
    "        \n",
    "        #Adding the labels to the arrays\n",
    "        label_subject_acquisition.append([label] *  (files_acquisition*epochs_acquisition))\n",
    "\n",
    "        #Adding it to the metadata\n",
    "        data_acquisition_list.append(data_subject_acquisition)\n",
    "\n",
    "\n",
    "        #Same for motor imagery\n",
    "        data_subject_MI = np.array(data_subject_MI)\n",
    "\n",
    "        #Reshaping motor imagery matrix\n",
    "        files_MI, epochs_MI, channels_MI, resolution_MI = data_subject_MI.shape\n",
    "        data_subject_MI = data_subject_MI.reshape((files_MI*epochs_MI, channels_MI, resolution_MI))\n",
    "\n",
    "        #Adding the labels to the arrays\n",
    "        label_subject_MI.append([label] *  (files_MI*epochs_MI))\n",
    "\n",
    "        #Adding it to the metadata\n",
    "        data_MI_list.append(data_subject_MI)\n",
    "        \n",
    "    #Creating the array and reshaping it to the good shape\n",
    "    events_acquisition = np.array(events_acquisition)\n",
    "    events_acquisition = events_acquisition.reshape(-1, 3)\n",
    "\n",
    "    events_MI = np.array(events_MI)\n",
    "    events_MI = events_MI.reshape(-1, 3)\n",
    "\n",
    "    return np.array(data_acquisition_list), np.array(data_MI_list), np.array(label_subject_acquisition), np.array(label_subject_MI), events_acquisition, events_MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f2c383f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Execution takes around 6mins\n",
    "data_array_acquisition, data_array_MI, label_array_acquisition, label_array_MI, events_acquisition, events_MI = read_all_data(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "0c00c541-bb0e-4002-b6da-ae381ae000b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the acquisition array (39, 80, 27, 4097)\n",
      "Shape of its label array (39, 80)\n",
      "\n",
      "Shape of the acquisition array (39, 160, 27, 4097)\n",
      "Shape of its label array (39, 160)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the acquisition array {data_array_acquisition.shape}\") # (# subjects, # windows per subject, # channels, resolution of the signal)\n",
    "print(f\"Shape of its label array {label_array_acquisition.shape}\\n\")    # (# subjects, # windows per subject)\n",
    "\n",
    "\n",
    "print(f\"Shape of the acquisition array {data_array_MI.shape}\") # (# subjects, # windows per subject, # channels, resolution of the signal)\n",
    "print(f\"Shape of its label array {label_array_MI.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fba4caec-f475-4d54-bb5d-33173cda09a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Events acquisition shape : (6240, 3)\n",
      "Events motor imagery shape : (12480, 3)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Events acquisition shape : {events_acquisition.shape}\")\n",
    "print(f\"Events motor imagery shape : {events_MI.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c083eb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_all_baseline(all_baselines):\n",
    "\n",
    "    #Label array to store every ID for each participant\n",
    "    label_subject_baseline = []\n",
    "\n",
    "    #Regex pattern to find the ID of the subject\n",
    "    pattern = r'A\\d+'\n",
    "\n",
    "    #Same function as before but for baseline files\n",
    "    data_baseline_list = []\n",
    "\n",
    "    for subject_files in all_baselines:\n",
    "\n",
    "        booleen = False\n",
    "        data_subject_baseline = []\n",
    "        label = re.findall(pattern, subject_files[0])[0]\n",
    "        \n",
    "        for j in subject_files:\n",
    "                        \n",
    "            data = read_baseline(j)\n",
    "            data_subject_baseline.append(data)\n",
    "\n",
    "            if data.shape[0] !=40:\n",
    "                booleen = True\n",
    "\n",
    "        #If the shape is different (for some reasons) we do not inclue the subject in the data\n",
    "        if booleen:\n",
    "            continue\n",
    "\n",
    "        #Creating the array and reshaping it (#files, # epochs, #channels, resolution) -> (#epochs * #files, #channels, #resolution\n",
    "        data_subject_baseline = np.array(data_subject_baseline)\n",
    "\n",
    "        #Reshaping it\n",
    "        files, epochs, channels, resolution = data_subject_baseline.shape\n",
    "        data_subject_baseline = data_subject_baseline.reshape((files * epochs, channels, resolution))\n",
    "        \n",
    "        #Annotation of every subject\n",
    "        label_subject_baseline.append([label] *  (files*epochs))\n",
    "\n",
    "        #Adding it to the metadata\n",
    "        data_baseline_list.append(data_subject_baseline)\n",
    "\n",
    "\n",
    "    return np.array(data_baseline_list), np.array(label_subject_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "96d77c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "data_array_baseline, label_array_baseline = read_all_baseline(baseline_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b1d46981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the baseline array (37, 80, 27, 2355)\n",
      "Shape of its label array (37, 80)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of the baseline array {data_array_baseline.shape}\") # (# subjects, # windows per subject, # channels, resolution of the signal)\n",
    "print(f\"Shape of its label array {label_array_baseline.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "25a9147f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects absents in the participants baseline due to some issues : ['A16', 'A30']\n"
     ]
    }
   ],
   "source": [
    "participants_baseline = np.unique(label_array_baseline)\n",
    "\n",
    "participants = np.unique(label_array_acquisition)\n",
    "\n",
    "absents = []\n",
    "for subject in participants:\n",
    "    if subject not in participants_baseline:\n",
    "        absents.append(subject)\n",
    "\n",
    "print(f\"Subjects absents in the participants baseline due to some issues : {absents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2c83e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline number of trials per participant : 80\n",
      "Acquisition number of trials per participant : 80\n",
      "Motor Imagery number of trials per participant : 160\n"
     ]
    }
   ],
   "source": [
    "print(f\"Baseline number of trials per participant : {label_array_baseline.shape[1]}\")\n",
    "print(f\"Acquisition number of trials per participant : {label_array_acquisition.shape[1]}\")\n",
    "print(f\"Motor Imagery number of trials per participant : {label_array_MI.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b9870c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline : (2960,)\n",
      "Acquisition : (3120,)\n",
      "Motor Imagery (6240,)\n"
     ]
    }
   ],
   "source": [
    "label_array_baseline = np.hstack(label_array_baseline)\n",
    "label_array_acquisition = np.hstack(label_array_acquisition)\n",
    "label_array_MI = np.hstack(label_array_MI)\n",
    "\n",
    "print(f\"Baseline : {label_array_baseline.shape}\")\n",
    "print(f\"Acquisition : {label_array_acquisition.shape}\")\n",
    "print(f\"Motor Imagery {label_array_MI.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "61e7ef20-ebf2-465c-a3e5-fb70297efae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2960, 27, 2355) (2960,)\n",
      "(3120, 27, 4097) (3120,)\n",
      "(6240, 27, 4097) (6240,)\n"
     ]
    }
   ],
   "source": [
    "#Create the storing folder if it does not exists\n",
    "if not os.path.exists('../Labels_arrays'):\n",
    "    os.makedirs('../Labels_arrays')\n",
    "\n",
    "if not os.path.exists('../Labels_arrays/Raw'):\n",
    "    os.makedirs('../Labels_arrays/Raw')\n",
    "\n",
    "data_array_baseline = np.vstack(data_array_baseline)\n",
    "\n",
    "#Saving the label for analysis\n",
    "np.savetxt('../Labels_arrays/Raw/Raw_label_array_baseline.txt', label_array_baseline, fmt='%s', delimiter=',')\n",
    "\n",
    "print(data_array_baseline.shape, label_array_baseline.shape)\n",
    "\n",
    "\n",
    "\n",
    "data_array_acquisition = np.vstack(data_array_acquisition)   #concatenate all lists vertically\n",
    "\n",
    "#Saving the label for analysis\n",
    "np.savetxt('../Labels_arrays/Raw/Raw_label_array_acquisition.txt', label_array_acquisition, fmt='%s', delimiter=',')\n",
    "\n",
    "print(data_array_acquisition.shape, label_array_acquisition.shape)\n",
    "\n",
    "\n",
    "\n",
    "data_array_MI = np.vstack(data_array_MI)   #concatenate all lists vertically\n",
    "\n",
    "#Saving the label for analysis\n",
    "np.savetxt('../Labels_arrays/Raw/Raw_label_array_MI.txt', label_array_MI, fmt='%s', delimiter=',')\n",
    "\n",
    "print(data_array_MI.shape, label_array_MI.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f1472029-5145-4554-8bac-62541e389482",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_baseline, resolution_baseline = data_array_baseline.shape[0], data_array_baseline.shape[2]\n",
    "\n",
    "windows_acquisition, channels, resolution = data_array_acquisition.shape\n",
    "\n",
    "windows_MI = data_array_MI.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd2cfda-fddc-485c-afb7-056448a79473",
   "metadata": {},
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "dd3a6fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to save dataframes/array into csv files\n",
    "def save_as_csv(X, filename):\n",
    "    \n",
    "    #Create the storing folder if it does not exists\n",
    "    if not os.path.exists('../Features_Dataframes'):\n",
    "        os.makedirs('../Features_Dataframes')\n",
    "\n",
    "    if not os.path.exists('../Features_Dataframes/Raw'):\n",
    "        os.makedirs('../Features_Dataframes/Raw')\n",
    "\n",
    "    X.to_csv(f'../Features_Dataframes/Raw/{filename}.csv', index=False)\n",
    "    print(f\"{filename} saved as .csv\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e3c09-29dc-4906-a5f7-558c05c03ee6",
   "metadata": {},
   "source": [
    "#### PSD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "f1b5331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import simps       #To integrate for each band\n",
    "from itertools import combinations      #To generate every combinations possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c70a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSD(x, windows = windows_MI, channels = channels):\n",
    "    '''WARNING : If using scipy 1.14.0 or latest version, use simpson function instead of simps'''\n",
    "    # PSD for each window of each channel\n",
    "    psd, freqs = mne.time_frequency.psd_array_multitaper(x=x, sfreq=sfreq, bandwidth=0.5, low_bias=True, normalization='full', n_jobs=-1)\n",
    "    \n",
    "    #Every bands analysized [gamma, beta, alpha, theta, delta]\n",
    "    bands = [(0.5, 4), (4, 8), (8, 12), (12, 35), (35, 60)]\n",
    "    band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "    n = len(bands)\n",
    "\n",
    "    #Creating matrix to store spectral_ratios\n",
    "    spectral_ratios = np.zeros((windows, channels, n, n))\n",
    "    spectral_powers = np.zeros((windows, channels, n))\n",
    "\n",
    "    names_ratio = [[[\"\" for i in range(5)] for j in range(5)] for k in range(channels)]\n",
    "    names_power = []\n",
    "\n",
    "    \n",
    "    #Setting the maximum frequency in the measured bands\n",
    "    fmin=bands[0][0]\n",
    "    fmax=bands[-1][1]\n",
    "    \n",
    "    for i, (fmin, fmax) in enumerate(bands):\n",
    "        \n",
    "        #Freq indices in the band\n",
    "        freq_idx = np.where((freqs >= fmin) & (freqs <= fmax))[0]\n",
    "\n",
    "        #Frequency resolution\n",
    "        freq_res = freq_idx[-1] - freq_idx[0]\n",
    "\n",
    "        #Spectral power (we integrate behind the curve on the frequencies intervall of the band)\n",
    "        spectral_power_band = simps(psd[:, :, freq_idx], dx=freq_res)\n",
    "\n",
    "        #Spectral power of the band\n",
    "        spectral_powers[:, :, i] = spectral_power_band\n",
    "\n",
    "        #Dimensions of the power array\n",
    "        x, y, z = spectral_powers.shape\n",
    "\n",
    "    #Assigning names (channel 1 - all bands, channel 2 - all bands, ...)\n",
    "    for j in range(channels):\n",
    "        power_band_names = [f\"Power channel {channel_names[j]} band {band_names[i]}\" for i in range(n)]\n",
    "        names_power.append(power_band_names)\n",
    "    \n",
    "    #We need to divide by the sum and not the total_power of the signal because simps is an approximation that does not work well on high resolution\n",
    "    spectral_powers = spectral_powers / np.sum(spectral_powers, axis=-1)[:, :, np.newaxis]\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            spectral_ratios[:, :, i, j] = spectral_powers[:, :, i] / spectral_powers[:, :, j]\n",
    "            spectral_ratios[:, :, j, i] = spectral_powers[:, :, j] / spectral_powers[:, :, i]\n",
    "\n",
    "    #Not optimal method since we re-parse the matrix ...\n",
    "    #But it works \n",
    "    for k in range(channels):\n",
    "        for i in range(n):\n",
    "            for j in range(i+1, n):\n",
    "\n",
    "                #Naming the ratios\n",
    "                names_ratio[k][i][j] = f\"Ratio channel {channel_names[k]} {band_names[i]}/{band_names[j]}\"\n",
    "                names_ratio[k][j][i] = f\"Ratio channel {channel_names[k]} {band_names[j]}/{band_names[i]}\"\n",
    "\n",
    "    #Deleting the diagonales which are equal to zero\n",
    "    spectral_ratios = spectral_ratios[np.nonzero(spectral_ratios)]\n",
    "    \n",
    "    columns = []\n",
    "    #Flattening the list of lists into one dimension list\n",
    "    for sublist in names_power:\n",
    "        columns.extend(sublist)\n",
    "\n",
    "    for sublist in names_ratio:\n",
    "        for sub in sublist:\n",
    "            columns.extend(sub)\n",
    "    \n",
    "    while \"\" in columns:\n",
    "        columns.remove(\"\")\n",
    "    \n",
    "    array = np.concatenate((spectral_powers.reshape((x, y*z)), spectral_ratios.reshape((x, y*(z**2 - z)))), axis=-1)\n",
    "    X = pd.DataFrame(array, columns=columns)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "39cfe8dc-2e0a-482b-81fb-842f33004d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Using multitaper spectrum estimation with 3 DPSS windows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_8796\\2427907505.py:32: DeprecationWarning: 'scipy.integrate.simps' is deprecated in favour of 'scipy.integrate.simpson' and will be removed in SciPy 1.14.0\n",
      "  spectral_power_band = simps(psd[:, :, freq_idx], dx=freq_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4400, 675)\n",
      "PSD_acquisition_MI_BCI saved as .csv\n",
      "    Using multitaper spectrum estimation with 3 DPSS windows\n",
      "(8800, 675)\n",
      "PSD_onlineT_MI_BCI saved as .csv\n",
      "    Using multitaper spectrum estimation with 1 DPSS windows\n",
      "(4160, 675)\n",
      "PSD_baseline_MI_BCI saved as .csv\n"
     ]
    }
   ],
   "source": [
    "#For acquisition\n",
    "X_PSD_acquisition = PSD(data_array_acquisition, windows=windows_acquisition)\n",
    "\n",
    "# (# of windows, 27*5*2)\n",
    "print(X_PSD_acquisition.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_PSD_acquisition, 'Raw_PSD_acquisition_MI_BCI')\n",
    "\n",
    "del X_PSD_acquisition\n",
    "\n",
    "#For Motor Imagery\n",
    "X_PSD_MI = PSD(data_array_MI)\n",
    "\n",
    "# (# of windows, 27*5*2)\n",
    "print(X_PSD_MI.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_PSD_MI, 'Raw_PSD_onlineT_MI_BCI')\n",
    "\n",
    "del X_PSD_MI\n",
    "\n",
    "#For baseline\n",
    "X_PSD_baseline = PSD(data_array_baseline, windows=windows_baseline, channels=channels)\n",
    "\n",
    "# (# of windows, 27*5*2)\n",
    "print(X_PSD_baseline.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_PSD_baseline, 'Raw_PSD_baseline_MI_BCI')\n",
    "\n",
    "del X_PSD_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6656fd3-2c68-4c52-bd77-65763b7e0f9d",
   "metadata": {},
   "source": [
    "#### Coherence feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "fd752613-8701-4d35-8fb4-68fd26f15883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import coherence\n",
    "\n",
    "def Coherence(data, windows = windows_MI, channels = channels):\n",
    "\n",
    "    total = ((channels**2-channels)/2)*5\n",
    "    print(f\"We will calculate {int(total)} coherence values\")\n",
    "\n",
    "    #Reminding of the band frequencies we're focused on\n",
    "    bands = [(1, 4), (4, 8), (8, 12), (12, 35), (35, 80)]\n",
    "    band_names = [\"delta\", \"theta\", \"alpha\", \"beta\", \"gamma\"]\n",
    "\n",
    "    #Creating a matrix for the coherence\n",
    "\n",
    "    n = int((channels**2-channels)/2)   #(channels**2 - channels )/ 2 equal the number of combinations of 2 channels without repetition\n",
    "    coh = np.zeros((windows, n, len(bands)))\n",
    "    coh_names = []\n",
    "\n",
    "\n",
    "    #For each pair of electrodes\n",
    "    comb = combinations(range(channels), 2)\n",
    "    \n",
    "    for c in comb:\n",
    "        x, y = c\n",
    "        #Calculate the coherence for every frequency found in the signal\n",
    "        coh_freq, cohe = coherence(data[:, x, :], data[:, y, :], fs=sfreq)\n",
    "\n",
    "        #Adjusting the index from (x, y) to z considering the triangular matrix of calculated coherence\n",
    "        idx = x * (channels - 1) - (x * (x - 1)) // 2 + y - (x + 1)\n",
    "        \n",
    "        #Calculate coherence for each band\n",
    "        for i, (fmin, fmax) in enumerate(bands):\n",
    "            freq_idx = np.where((coh_freq >= fmin) & (coh_freq <= fmax))[0]\n",
    "            \n",
    "            #Here we calculate the coherence of the band by the mean but we could also use an integral\n",
    "            coh_band = np.mean(cohe[:, freq_idx], axis=-1)\n",
    "            \n",
    "            coh[:, idx, i] = coh_band\n",
    "\n",
    "            #Namming each feature so we can retrieve which ones are the best for classification\n",
    "            coh_names.append(f\"Coherence channels {channel_names[x]}-{channel_names[y]} band {band_names[i]}\")\n",
    "    \n",
    "    array = coh.reshape(windows, n*len(bands))\n",
    "    X = pd.DataFrame(array, columns=coh_names)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "41cce141-6ecc-4732-ba52-4cbba31474ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We will calculate 1755 coherence values\n",
      "(4400, 1755)\n",
      "COH_acquisition_MI_BCI saved as .csv\n",
      "We will calculate 1755 coherence values\n",
      "(8800, 1755)\n",
      "COH_onlineT_MI_BCI saved as .csv\n",
      "We will calculate 1755 coherence values\n",
      "(4160, 1755)\n",
      "COH_baseline_MI_BCI saved as .csv\n"
     ]
    }
   ],
   "source": [
    "#Atleast 1hour execution time\n",
    "\n",
    "#For acquisition\n",
    "X_COH_acquisition = Coherence(data_array_acquisition, windows=windows_acquisition)\n",
    "\n",
    "# (# of windows, # of comb * # of bands)\n",
    "print(X_COH_acquisition.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_COH_acquisition, 'Raw_COH_acquisition_MI_BCI')\n",
    "\n",
    "del X_COH_acquisition\n",
    "\n",
    "#For Motor Imagery\n",
    "X_COH_MI = Coherence(data_array_MI)\n",
    "\n",
    "# (# of windows, # of comb * # of bands)\n",
    "print(X_COH_MI.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_COH_MI, 'Raw_COH_onlineT_MI_BCI')\n",
    "\n",
    "del X_COH_MI\n",
    "\n",
    "#For baseline\n",
    "X_COH_baseline = Coherence(data_array_baseline, windows=windows_baseline, channels=channels)\n",
    "\n",
    "# (# of windows, # of comb * # of bands)\n",
    "print(X_COH_baseline.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_COH_baseline, 'Raw_COH_baseline_MI_BCI')\n",
    "\n",
    "del X_COH_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb8e95c",
   "metadata": {},
   "source": [
    "Function to avoid overfitting on the CSP features (we have to separate the 6 patterns for very fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "e806d583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def events_buckets(array, events, label, bins=5):\n",
    "    # This function takes an epochs array, a label array and the integer bins and return the array buckets which store 5 bins (default) for every subject\n",
    "    # (epochs, channels, resolution) * (epochs) * int -> (int, epochs//int, channels, resolution) * (int, epochs)\n",
    "\n",
    "    classes = np.unique(label)\n",
    "\n",
    "    x, y, z = array.shape\n",
    "    buckets = np.zeros((bins, x//bins, y, z))\n",
    "\n",
    "    events_labels = events[(events[:, 2] == 1) | (events[:, 2] == 2), -1]\n",
    "\n",
    "    #Re-referencing the data since we merge them with other subjects\n",
    "    buckets_events = np.zeros((bins, x//bins), dtype=int)\n",
    "\n",
    "    #Separating for each subject\n",
    "    for i in range(len(classes)):\n",
    "        \n",
    "        #Index of the epochs of the specified subject\n",
    "        idx_epochs = np.where(label==classes[i])[0]\n",
    "        n = len(idx_epochs)\n",
    "\n",
    "        #Separating each subject into 5 bins\n",
    "        for j in range(bins):\n",
    "            index = idx_epochs[n//bins * j : n//bins * (j+1)]\n",
    "            l = len(index)            \n",
    "            buckets[j, l*i:l*(i+1), :, :] = array[index, :]\n",
    "            buckets_events[j, l*i:l*(i+1)] = events_labels[index]\n",
    "\n",
    "    return buckets, buckets_events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea2a03f-ed68-44e3-8f43-7d9833e140b6",
   "metadata": {},
   "source": [
    "#### CSP feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "21d8bdd6-fa66-4c64-8198-b8af924f059e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSP(x, events, labels, bins=5):\n",
    "\n",
    "    buckets, buckets_events = events_buckets(x, events, labels, bins=bins)\n",
    "    DF = []\n",
    "\n",
    "    for i in tqdm(range(bins)):\n",
    "\n",
    "        # Separating into bins-1 buckets as training\n",
    "        index = [k for k in range(bins) if k != i]\n",
    "        X = np.concatenate(buckets[index])\n",
    "        y = np.concatenate(buckets_events[index])\n",
    "        \n",
    "        #Taking the last fold as the testing one\n",
    "        X_test = buckets[i]\n",
    "\n",
    "        # CSP calculation\n",
    "        csp = mne.decoding.CSP(n_components=6, reg=0.01, log=True, norm_trace=True, rank={'eeg': 27, 'mag':27})\n",
    "        \n",
    "        # Fit CSP on epochs data\n",
    "        csp.fit(X, y)\n",
    "\n",
    "        # Apply CSP to epochs\n",
    "        epochs_csp = csp.transform(X_test)\n",
    "\n",
    "        columns = [f\"CSP Pattern nÂ°{k+1}\" for k in range(epochs_csp.shape[1])]\n",
    "\n",
    "        df = pd.DataFrame(epochs_csp, columns=columns)\n",
    "\n",
    "        DF.append(df)\n",
    "\n",
    "    return pd.concat(DF, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "faed53e8-ffb5-45ce-b0ce-658937070410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|ââ        | 1/5 [00:43<02:54, 43.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|ââââ      | 2/5 [01:04<01:31, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|ââââââ    | 3/5 [01:24<00:51, 25.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|ââââââââ  | 4/5 [01:45<00:23, 23.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 5/5 [02:05<00:00, 25.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 6)\n",
      "CSP_acquisition_MI_BCI saved as .csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|ââ        | 1/5 [1:02:59<4:11:58, 3779.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|ââââ      | 2/5 [1:12:10<1:34:01, 1880.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|ââââââ    | 3/5 [1:17:13<38:39, 1159.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|ââââââââ  | 4/5 [1:25:32<14:58, 898.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n",
      "Computing rank from data with rank={'eeg': 27, 'mag': 27}\n",
      "    Setting small MAG eigenvalues to zero (without PCA)\n",
      "Reducing data rank from 27 -> 27\n",
      "Estimating covariance using SHRINKAGE\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|ââââââââââ| 5/5 [1:30:23<00:00, 1084.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 6)\n",
      "CSP_onlineT_MI_BCI saved as .csv\n"
     ]
    }
   ],
   "source": [
    "#For acquisition\n",
    "X_CSP_acquisition = CSP(data_array_acquisition, events_acquisition, label_array_acquisition)\n",
    "\n",
    "# (# windows, 6)\n",
    "print(X_CSP_acquisition.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_CSP_acquisition, 'Raw_CSP_acquisition_MI_BCI')\n",
    "\n",
    "#To save memory\n",
    "del X_CSP_acquisition\n",
    "\n",
    "\n",
    "#For Motor Imagery\n",
    "X_CSP_MI= CSP(data_array_MI, events_MI, label_array_MI)\n",
    "\n",
    "# (# windows, 6)\n",
    "print(X_CSP_MI.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_CSP_MI, 'Raw_CSP_onlineT_MI_BCI')\n",
    "\n",
    "#Saving memory\n",
    "del X_CSP_MI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6b7c42-cf0d-448a-98b8-4e4f793fe76a",
   "metadata": {},
   "source": [
    "#### Inter-hemispheric amplitude ratio (IHAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "c53f35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to compute amplitude on the left/right electrodes\n",
    "def compute_amplitude_rms(signal):\n",
    "    return np.sqrt(np.mean(np.square(signal), axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "66a235da-1ffc-4759-b7a7-fe1f3347ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IHAR(x, n=11):\n",
    "    #x = (epochs, channels, resolution)\n",
    "    #n = number of bilateral pair you want to select\n",
    "    info = mne.create_info(ch_names=channel_names, sfreq=sfreq, ch_types='eeg')\n",
    "    epochs = mne.EpochsArray(x, info)\n",
    "    \n",
    "    left = ['F3', 'FC5', 'FC3', 'FC1', 'C5', 'C3', 'C1', 'CP5', 'CP3', 'CP1', 'P3']  #Left  hemisphere\n",
    "    right= ['F4', 'FC2', 'FC4', 'FC6', 'C2', 'C4', 'C6', 'CP2', 'CP4', 'CP6', 'P4']  #Right hemisphere\n",
    "\n",
    "    #Computing the rms amplitudes for every left channel\n",
    "    left_amplitude = epochs.copy().pick_channels(left[:n]).get_data()\n",
    "    left_amplitude = compute_amplitude_rms(left_amplitude)\n",
    "\n",
    "    #Same for right channels\n",
    "    right_amplitude = epochs.copy().pick_channels(right[:n]).get_data()\n",
    "    right_amplitude = compute_amplitude_rms(right_amplitude)\n",
    "    \n",
    "    IHAR_values = left_amplitude / right_amplitude\n",
    "    \n",
    "    columns = [f\"IHAR : {left[i]}/{right[i]}\" for i in range(n)]\n",
    "    X = pd.DataFrame(IHAR_values, columns=columns)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "60a412f4-7972-4791-8f11-9e17dbefb245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "4320 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:11: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  left_amplitude = epochs.copy().pick_channels(left[:n]).get_data()\n",
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:11: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  left_amplitude = epochs.copy().pick_channels(left[:n]).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:15: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  right_amplitude = epochs.copy().pick_channels(right[:n]).get_data()\n",
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:15: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  right_amplitude = epochs.copy().pick_channels(right[:n]).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4320, 11)\n",
      "IHAR_acquisition_MI_BCI saved as .csv\n",
      "Not setting metadata\n",
      "8640 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:11: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  left_amplitude = epochs.copy().pick_channels(left[:n]).get_data()\n",
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:11: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  left_amplitude = epochs.copy().pick_channels(left[:n]).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:15: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  right_amplitude = epochs.copy().pick_channels(right[:n]).get_data()\n",
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:15: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  right_amplitude = epochs.copy().pick_channels(right[:n]).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8640, 11)\n",
      "IHAR_onlineT_MI_BCI saved as .csv\n",
      "Not setting metadata\n",
      "4160 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:11: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  left_amplitude = epochs.copy().pick_channels(left[:n]).get_data()\n",
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:11: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  left_amplitude = epochs.copy().pick_channels(left[:n]).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:15: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  right_amplitude = epochs.copy().pick_channels(right[:n]).get_data()\n",
      "C:\\Users\\gricih01\\AppData\\Local\\Temp\\ipykernel_15276\\1680328372.py:15: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  right_amplitude = epochs.copy().pick_channels(right[:n]).get_data()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4160, 11)\n",
      "IHAR_baseline_MI_BCI saved as .csv\n"
     ]
    }
   ],
   "source": [
    "#For acquisition\n",
    "X_IHAR_acquisition = IHAR(data_array_acquisition)\n",
    "\n",
    "# (# of windows, 1)\n",
    "print(X_IHAR_acquisition.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_IHAR_acquisition, 'Raw_IHAR_acquisition_MI_BCI')\n",
    "\n",
    "del X_IHAR_acquisition\n",
    "\n",
    "\n",
    "#For Motor Imagery\n",
    "X_IHAR_MI = IHAR(data_array_MI)\n",
    "\n",
    "# (# of windows, 1)\n",
    "print(X_IHAR_MI.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_IHAR_MI, 'Raw_IHAR_onlineT_MI_BCI')\n",
    "\n",
    "del X_IHAR_MI\n",
    "\n",
    "\n",
    "#For baseline\n",
    "X_IHAR_baseline = IHAR(data_array_baseline)\n",
    "\n",
    "# (# of windows, 1)\n",
    "print(X_IHAR_baseline.shape)\n",
    "\n",
    "#Saving the df\n",
    "save_as_csv(X_IHAR_baseline, 'Raw_IHAR_baseline_MI_BCI')\n",
    "\n",
    "del X_IHAR_baseline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
